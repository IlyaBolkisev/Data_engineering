{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211bc652",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6002eec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1cf9d004640>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('database.db')\n",
    "cur = conn.cursor()\n",
    "sql = \"\"\"\n",
    "    CREATE TABLE DataTable1 (\n",
    "        title TEXT,\n",
    "        author TEXT,\n",
    "        genre TEXT,\n",
    "        pages INTEGER, \n",
    "        published_year INTEGER,\n",
    "        isbn TEXT,\n",
    "        rating FLOAT,\n",
    "        views INTEGER\n",
    "        )\"\"\"\n",
    "\n",
    "cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "608fbbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./1/task_1_var_02_item.text', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for item in [[lines[i*9+j].strip().split('::')[-1] for j in range(8)] for i in range(len(lines)//9)]:\n",
    "    cur.execute(\"\"\"INSERT INTO DataTable1 VALUES (\n",
    "        :title,\n",
    "        :author,\n",
    "        :genre,\n",
    "        :pages, \n",
    "        :published_year,\n",
    "        :isbn,\n",
    "        :rating,\n",
    "        :views)\"\"\", item)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6606c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_from_head(conn, sort_col, n):\n",
    "    cur = conn.cursor()\n",
    "    samples = cur.execute(f\"\"\"SELECT title,\n",
    "        author,\n",
    "        genre,\n",
    "        pages, \n",
    "        published_year,\n",
    "        isbn,\n",
    "        rating,\n",
    "        views \n",
    "        FROM DataTable1 ORDER BY {sort_col} DESC LIMIT {str(n)}\"\"\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "cur = get_from_head(conn, 'rating', 12)\n",
    "\n",
    "keys = ['title', 'author', 'genre', 'pages', 'published_year', 'isbn', 'rating', 'views']\n",
    "result = []\n",
    "for row in cur.fetchall():\n",
    "    result.append({keys[i]: str(e) for i, e in enumerate(row)})\n",
    "    \n",
    "with open(\"1_top.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(result, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a265df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(conn, col):\n",
    "    cur = conn.cursor()\n",
    "    stats = cur.execute(f\"\"\"SELECT \n",
    "        SUM({col}), MIN({col}), MAX({col}), AVG({col})  \n",
    "        FROM DataTable1\"\"\")\n",
    "    return stats.fetchone()\n",
    "\n",
    "stats = get_stats(conn, 'rating')\n",
    "keys = ['sum', 'min', 'max', 'avg']\n",
    "\n",
    "with open(\"1_stats.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump({keys[i]: str(e) for i, e in enumerate(stats)}, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad91ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(conn, col):\n",
    "    cur = conn.cursor()\n",
    "    freq = cur.execute(f\"\"\"SELECT \n",
    "        {col}, COUNT(*)\n",
    "        FROM DataTable1 GROUP BY {col}\"\"\")\n",
    "    return freq\n",
    "\n",
    "freq = get_freq(conn, 'genre')\n",
    "freq = {e[0]: str(e[1]) for e in freq}\n",
    "\n",
    "with open(\"1_freq.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(freq, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8846bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_head_with_condition(conn, sort_col, n, condition):\n",
    "    cur = conn.cursor()\n",
    "    samples = cur.execute(f\"\"\"SELECT title,\n",
    "        author,\n",
    "        genre,\n",
    "        pages, \n",
    "        published_year,\n",
    "        isbn,\n",
    "        rating,\n",
    "        views \n",
    "        FROM DataTable1 WHERE {condition} ORDER BY {sort_col} DESC LIMIT {str(n)}\"\"\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "cur = get_from_head_with_condition(conn, 'rating', 12, 'published_year > 1900')\n",
    "\n",
    "keys = ['title', 'author', 'genre', 'pages', 'published_year', 'isbn', 'rating', 'views']\n",
    "result = []\n",
    "for row in cur.fetchall():\n",
    "    result.append({keys[i]: str(e) for i, e in enumerate(row)})\n",
    "    \n",
    "with open(\"1_top_with_condition.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(result, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e6ae3",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c95758fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1cf9d0851c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    CREATE TABLE DataTable2 (\n",
    "        title TEXT,\n",
    "        price INTEGER,\n",
    "        place TEXT,\n",
    "        data DATETIME\n",
    "        )\"\"\"\n",
    "\n",
    "cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "636206d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Дюна', 'price': 4368, 'place': 'offline', 'date': '3.5.2014'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import msgpack\n",
    "    \n",
    "with open(\"./2/task_2_var_02_subitem.msgpack\", \"rb\") as data_file:\n",
    "    byte_data = data_file.read()\n",
    "    data = msgpack.unpackb(byte_data)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74763b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data:\n",
    "    cur.execute(\"\"\"INSERT INTO DataTable2 VALUES (\n",
    "        :title,\n",
    "        :price,\n",
    "        :place,\n",
    "        :data)\"\"\", list(item.values()))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b64cd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_head_both(conn, n):\n",
    "    cur = conn.cursor()\n",
    "    samples = cur.execute(f\"\"\"SELECT DataTable1.title,\n",
    "        DataTable1.author,\n",
    "        DataTable1.genre,\n",
    "        DataTable1.pages, \n",
    "        DataTable1.published_year,\n",
    "        DataTable1.isbn,\n",
    "        DataTable1.rating,\n",
    "        DataTable1.views,\n",
    "        DataTable2.price,\n",
    "        DataTable2.place,\n",
    "        DataTable2.data        \n",
    "        FROM DataTable1 JOIN DataTable2 ON DataTable1.title = DataTable2.title\"\"\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "cur = get_from_head_both(conn, 12)\n",
    "\n",
    "keys = ['title', 'author', 'genre', 'pages', 'published_year', 'isbn', 'rating', 'views', 'price', 'place', 'data']\n",
    "result = []\n",
    "for row in cur.fetchall():\n",
    "    result.append({keys[i]: str(e) for i, e in enumerate(row)})\n",
    "    \n",
    "with open(\"2_top_from_both.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(result, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45798511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_head_both_with_condition(conn, n, condition):\n",
    "    cur = conn.cursor()\n",
    "    samples = cur.execute(f\"\"\"SELECT DataTable1.title,\n",
    "        DataTable1.author,\n",
    "        DataTable1.genre,\n",
    "        DataTable1.pages, \n",
    "        DataTable1.published_year,\n",
    "        DataTable1.isbn,\n",
    "        DataTable1.rating,\n",
    "        DataTable1.views,\n",
    "        DataTable2.price,\n",
    "        DataTable2.place,\n",
    "        DataTable2.data        \n",
    "        FROM DataTable1 JOIN DataTable2 ON DataTable1.title = DataTable2.title\n",
    "        WHERE {condition}\"\"\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "cur = get_from_head_both_with_condition(conn, 12, 'DataTable2.price > 1000')\n",
    "\n",
    "keys = ['title', 'author', 'genre', 'pages', 'published_year', 'isbn', 'rating', 'views', 'price', 'place', 'data']\n",
    "result = []\n",
    "for row in cur.fetchall():\n",
    "    result.append({keys[i]: str(e) for i, e in enumerate(row)})\n",
    "    \n",
    "with open(\"2_top_from_both_with_condition.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(result, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aff5ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_head_both_ordered(conn, n, sort_col):\n",
    "    cur = conn.cursor()\n",
    "    samples = cur.execute(f\"\"\"SELECT DataTable1.title,\n",
    "        DataTable1.author,\n",
    "        DataTable1.genre,\n",
    "        DataTable1.pages, \n",
    "        DataTable1.published_year\n",
    "        FROM DataTable1 JOIN DataTable2 ON DataTable1.title = DataTable2.title\n",
    "        ORDER BY {sort_col}\"\"\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "cur = get_from_head_both_ordered(conn, 12, 'DataTable2.price')\n",
    "\n",
    "keys = ['title', 'author', 'genre', 'pages', 'published_year']\n",
    "result = []\n",
    "for row in cur.fetchall():\n",
    "    result.append({keys[i]: str(e) for i, e in enumerate(row)})\n",
    "    \n",
    "with open(\"2_top_from_both_ordered.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(result, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e2ff5",
   "metadata": {},
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0ae3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 802)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"3/task_3_var_02_part_1.json\", encoding='utf-8') as f:\n",
    "    part1 = json.load(f)\n",
    "    \n",
    "import msgpack\n",
    "    \n",
    "with open(\"3/task_3_var_02_part_2.msgpack\", \"rb\") as data_file:\n",
    "    byte_data = data_file.read()\n",
    "    part2 = msgpack.unpackb(byte_data)\n",
    "len(part1), len(part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb1fa582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_keys = ['artist', 'song', 'duration_ms', 'year', 'tempo', 'genre']\n",
    "\n",
    "result = [{key: e[key] for key in common_keys} for e in part1] + [{key: e[key] for key in common_keys} for e in part2]\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a48c9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1cf9d0047c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    CREATE TABLE DataTable3 (\n",
    "        artist TEXT, \n",
    "        song TEXT, \n",
    "        duration_ms INTEGER,\n",
    "        year INTEGER,\n",
    "        tempo FLOAT, \n",
    "        genre TEXT\n",
    "        )\"\"\"\n",
    "\n",
    "cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78a70afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in result:\n",
    "    cur.execute(\"\"\"INSERT INTO DataTable3 VALUES (\n",
    "        :artist,\n",
    "        :song,\n",
    "        :duration_ms,\n",
    "        :year, \n",
    "        :tempo,\n",
    "        :genre)\"\"\", list(item.values()))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7ac7f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_head(conn, sort_col, n):\n",
    "    cur = conn.cursor()\n",
    "    samples = cur.execute(f\"\"\"SELECT artist,\n",
    "        song,\n",
    "        duration_ms,\n",
    "        year, \n",
    "        tempo,\n",
    "        genre\n",
    "        FROM DataTable3 ORDER BY {sort_col} DESC LIMIT {str(n)}\"\"\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "cur = get_from_head(conn, 'year', 12)\n",
    "\n",
    "keys = ['title', 'author', 'genre', 'pages', 'published_year', 'isbn', 'rating', 'views']\n",
    "result = []\n",
    "for row in cur.fetchall():\n",
    "    result.append({keys[i]: str(e) for i, e in enumerate(row)})\n",
    "    \n",
    "with open(\"3_top.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(result, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "040d5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(conn, col):\n",
    "    cur = conn.cursor()\n",
    "    stats = cur.execute(f\"\"\"SELECT \n",
    "        SUM({col}), MIN({col}), MAX({col}), AVG({col})  \n",
    "        FROM DataTable3\"\"\")\n",
    "    return stats.fetchone()\n",
    "\n",
    "stats = get_stats(conn, 'duration_ms')\n",
    "keys = ['sum', 'min', 'max', 'avg']\n",
    "\n",
    "with open(\"3_stats.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump({keys[i]: str(e) for i, e in enumerate(stats)}, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76d57070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(conn, col):\n",
    "    cur = conn.cursor()\n",
    "    freq = cur.execute(f\"\"\"SELECT \n",
    "        {col}, COUNT(*)\n",
    "        FROM DataTable3 GROUP BY {col}\"\"\")\n",
    "    return freq\n",
    "\n",
    "freq = get_freq(conn, 'artist')\n",
    "freq = {e[0]: str(e[1]) for e in freq}\n",
    "\n",
    "with open(\"3_freq.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(freq, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09d1115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_head_with_condition(conn, sort_col, n, condition):\n",
    "    cur = conn.cursor()\n",
    "    samples = cur.execute(f\"\"\"SELECT artist,\n",
    "        song,\n",
    "        duration_ms,\n",
    "        year, \n",
    "        tempo,\n",
    "        genre\n",
    "        FROM DataTable3 WHERE {condition} ORDER BY {sort_col} DESC LIMIT {str(n)}\"\"\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "cur = get_from_head_with_condition(conn, 'year', 17, 'genre == \"rock, pop\"')\n",
    "\n",
    "keys = ['title', 'author', 'genre', 'pages', 'published_year', 'isbn', 'rating', 'views']\n",
    "result = []\n",
    "for row in cur.fetchall():\n",
    "    result.append({keys[i]: str(e) for i, e in enumerate(row)})\n",
    "    \n",
    "with open(\"3_top_with_condition.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(result, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fbf43e",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbd91bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./4/task_4_var_02_product_data.pkl', \"rb\") as f:\n",
    "    product_data = pickle.load(f)\n",
    "with open('./4/task_4_var_02_update_data.json', encoding='utf-8') as f:\n",
    "    update_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8f02bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fill_dict(d, keys):\n",
    "    for key in keys:\n",
    "        if key not in d:\n",
    "            d[key] = None\n",
    "    return d\n",
    "\n",
    "\n",
    "keys = np.unique([key for e in product_data for key in e.keys()])\n",
    "product_data = [fill_dict(e, keys) for e in product_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "287e4025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1cf9e933440>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    CREATE TABLE DataTable4 (\n",
    "        name TEXT, \n",
    "        price FLOAT, \n",
    "        quantity INTEGER,\n",
    "        category TEXT,\n",
    "        fromCity TEXT, \n",
    "        isAvailable BOOLEAN,\n",
    "        views INTEGER,\n",
    "        updates INTEGER \n",
    "        )\"\"\"\n",
    "\n",
    "cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb3d897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in product_data:\n",
    "    cur.execute(\"\"\"INSERT INTO DataTable4 VALUES (\n",
    "        :name, \n",
    "        :price, \n",
    "        :quantity,\n",
    "        :category,\n",
    "        :fromCity, \n",
    "        :isAvailable,\n",
    "        :views,\n",
    "        :updates)\"\"\", list(item.values()) + [0])\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ecd2fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['available', 'price_abs', 'price_percent', 'quantity_add',\n",
       "       'quantity_sub', 'remove'], dtype='<U13')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([e['method'] for e in update_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "814588ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_available(conn, col, param):\n",
    "    cur = conn.cursor()\n",
    "    res = cur.execute(f\"UPDATE DataTable4 SET isAvailable = {param} WHERE (name = \\\"{col}\\\")\")\n",
    "    cur.execute(f\"UPDATE DataTable4 SET updates = updates + 1 WHERE name = \\\"{col}\\\"\")\n",
    "    conn.commit()\n",
    "    \n",
    "\n",
    "def update_price_abs(conn, col, param):\n",
    "    cur = conn.cursor()\n",
    "    if param[0] != '-':\n",
    "        param = '+' + param\n",
    "    res = cur.execute(f\"UPDATE DataTable4 SET price = (price {param}) WHERE (name = \\\"{col}\\\") AND ((price {param}) > 0)\")\n",
    "    if res.rowcount > 0:\n",
    "        cur.execute(f\"UPDATE DataTable4 SET updates = updates + 1 WHERE name = \\\"{col}\\\"\")\n",
    "        conn.commit()\n",
    "\n",
    "    \n",
    "def update_price_percent(conn, col, param):\n",
    "    cur = conn.cursor()\n",
    "    res = cur.execute(f\"UPDATE DataTable4 SET price = ROUND((price * (1 + {param})), 2) WHERE (name = \\\"{col}\\\") AND ((1 + {param}) > 0)\")\n",
    "    if res.rowcount > 0:\n",
    "        cur.execute(f\"UPDATE DataTable4 SET updates = updates + 1 WHERE name = \\\"{col}\\\"\")\n",
    "        conn.commit()\n",
    "\n",
    "    \n",
    "def update_quantity(conn, col, param):\n",
    "    cur = conn.cursor()\n",
    "    if param[0] != '-':\n",
    "        param = '+' + param\n",
    "    res = cur.execute(f\"UPDATE DataTable4 SET quantity = (quantity {param}) WHERE (name = \\\"{col}\\\") AND ((quantity {param}) > 0)\")\n",
    "    if res.rowcount > 0:\n",
    "        cur.execute(f\"UPDATE DataTable4 SET updates = updates + 1 WHERE name = \\\"{col}\\\"\")\n",
    "        conn.commit()\n",
    "    \n",
    "    \n",
    "def delete_by_col(conn, col):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"DELETE FROM DataTable4 WHERE name = \\\"{col}\\\"\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e4b9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for update in update_data:\n",
    "    name, method, param = update.values()\n",
    "    param = str(param)\n",
    "    if method == 'available':\n",
    "        update_available(conn, name, param)\n",
    "    elif method == 'price_abs':\n",
    "        update_price_abs(conn, name, param)\n",
    "    elif method == 'price_percent':\n",
    "        update_price_percent(conn, name, param)\n",
    "    elif method == 'quantity_add':\n",
    "        update_quantity(conn, name, param)\n",
    "    elif method == 'quantity_sub':\n",
    "        update_quantity(conn, name, param)\n",
    "    elif method == 'remove':\n",
    "        delete_by_col(conn, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c75a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_head(conn, sort_col, n):\n",
    "    cur = conn.cursor()\n",
    "    samples = cur.execute(f\"\"\"SELECT \n",
    "        name, \n",
    "        price, \n",
    "        quantity,\n",
    "        category,\n",
    "        fromCity, \n",
    "        isAvailable,\n",
    "        views,\n",
    "        updates\n",
    "        FROM DataTable4 ORDER BY {sort_col} DESC LIMIT {str(n)}\"\"\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "cur = get_from_head(conn, 'updates', 10)\n",
    "\n",
    "keys = ['name', 'price', 'quantity', 'category', 'fromCity', 'isAvailable', 'views', 'updates']\n",
    "result = []\n",
    "for row in cur.fetchall():\n",
    "    result.append({keys[i]: str(e) for i, e in enumerate(row)})\n",
    "    \n",
    "with open(\"4_top.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(result, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31e2cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_for_categories(conn, col):\n",
    "    cur = conn.cursor()\n",
    "    stats = cur.execute(f\"\"\"SELECT \n",
    "        category, SUM({col}), MIN({col}), MAX({col}), AVG({col}), COUNT(*)  \n",
    "        FROM DataTable4 GROUP BY category\"\"\")\n",
    "    return stats.fetchall()\n",
    "\n",
    "stats = get_stats_for_categories(conn, 'price')\n",
    "keys = ['category', 'sum', 'min', 'max', 'avg', 'count']\n",
    "\n",
    "with open(\"4_stats_for_categories.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump([{keys[i]: str(e) for i, e in enumerate(category)} for category in stats], outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47a7779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(conn, col):\n",
    "    cur = conn.cursor()\n",
    "    stats = cur.execute(f\"\"\"SELECT \n",
    "        SUM({col}), MIN({col}), MAX({col}), AVG({col})  \n",
    "        FROM DataTable4\"\"\")\n",
    "    return stats.fetchone()\n",
    "\n",
    "stats = get_stats(conn, 'price')\n",
    "keys = ['sum', 'min', 'max', 'avg']\n",
    "\n",
    "with open(\"4_stats_.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump({keys[i]: str(e) for i, e in enumerate(stats)}, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebb24abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(conn, col):\n",
    "    cur = conn.cursor()\n",
    "    freq = cur.execute(f\"\"\"SELECT \n",
    "        {col}, COUNT(*)\n",
    "        FROM DataTable4 GROUP BY {col}\"\"\")\n",
    "    return freq\n",
    "\n",
    "freq = get_freq(conn, 'updates')\n",
    "freq = {e[0]: str(e[1]) for e in freq}\n",
    "\n",
    "with open(\"4_freq.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(freq, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02f0f6",
   "metadata": {},
   "source": [
    "# Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "374a3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# anime = pd.read_csv('./data/anime.csv').replace('Unknown', np.nan).dropna()\n",
    "# anime.to_csv('./data/anime.csv', index=False)\n",
    "anime = pd.read_csv('./data/anime.csv')\n",
    "\n",
    "# ws = pd.read_csv('./data/animelist.csv')\n",
    "# user_ids = ws['user_id'].unique()[:1000]\n",
    "# ws = ws[ws.user_id.isin(user_ids)]\n",
    "# ws.to_csv('./data/animelist.csv', index=False)\n",
    "ws = pd.read_csv('./data/animelist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce925cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(conn, sql):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "717fc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('database_custom.db')\n",
    "create_table(conn, \"\"\"CREATE TABLE AnimeInfo (\n",
    "        id INTEGER,\n",
    "        title TEXT,\n",
    "        score TEXT,\n",
    "        genres TEXT,\n",
    "        type TEXT,\n",
    "        episodes INTEGER, \n",
    "        producers TEXT,\n",
    "        rating TEXT\n",
    "        )\"\"\")\n",
    "\n",
    "create_table(conn, \"\"\"CREATE TABLE AnimeStats (\n",
    "        id INTEGER,\n",
    "        members INTEGER,\n",
    "        favorites INTEGER,\n",
    "        watching INTEGER,\n",
    "        completed INTEGER,\n",
    "        on_hold INTEGER,\n",
    "        dropped INTEGER,\n",
    "        plan_to_watch INTEGER,\n",
    "        score_10 FLOAT,\n",
    "        score_9 FLOAT,\n",
    "        score_8 FLOAT,\n",
    "        score_7 FLOAT,\n",
    "        score_6 FLOAT,\n",
    "        score_5 FLOAT,\n",
    "        score_4 FLOAT,\n",
    "        score_3 FLOAT,\n",
    "        score_2 FLOAT,\n",
    "        score_1 FLOAT\n",
    "        )\"\"\")\n",
    "\n",
    "create_table(conn, \"\"\"CREATE TABLE UserRating (\n",
    "        user_id INTEGER,\n",
    "        anime_id INTEGER,\n",
    "        rating INTEGER,\n",
    "        watching_status INTEGER\n",
    "        )\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9337699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_df(df, columns, res_keys):\n",
    "    data = df[columns].to_dict()\n",
    "    keys = list(data.keys())\n",
    "    n = len(data[keys[0]])\n",
    "    return [{res_keys[i] : data[key][j] for i, key in enumerate(keys)} for j in range(n)]\n",
    "\n",
    "\n",
    "def insert_data(conn, data, sql):\n",
    "    cur = conn.cursor()\n",
    "    cur.executemany(sql, data)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80bdf123",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_info_columns = ['MAL_ID', 'Name', 'Score', 'Genres', 'Type','Episodes', 'Producers','Rating']\n",
    "anime_info_keys = ['id', 'title', 'score', 'genres', 'type', 'episodes', 'producers', 'rating']\n",
    "anime_stats_columns = ['MAL_ID', 'Members', 'Favorites', 'Watching', 'Completed', 'On-Hold', 'Dropped', \n",
    "                       'Plan to Watch', 'Score-10', 'Score-9', 'Score-8', 'Score-7', 'Score-6', 'Score-5',\n",
    "                       'Score-4', 'Score-3', 'Score-2', 'Score-1']\n",
    "anime_stats_keys = ['id', 'members', 'favorites', 'watching', 'completed', 'on_hold', \n",
    "                    'dropped', 'plan_to_watch', 'score_10', 'score_9', 'score_8', 'score_7', \n",
    "                    'score_6', 'score_5', 'score_4', 'score_3', 'score_2', 'score_1']\n",
    "user_rating_columns = ['user_id', 'anime_id', 'rating', 'watching_status']\n",
    "user_rating_keys = ['user_id', 'anime_id', 'rating', 'watching_status']\n",
    "\n",
    "data1 = parse_df(anime, anime_info_columns, anime_info_keys)\n",
    "data2 = parse_df(anime, anime_stats_columns, anime_stats_keys)\n",
    "data3 = parse_df(ws, user_rating_columns, user_rating_keys)\n",
    "\n",
    "insert_data(conn, \n",
    "            data1, \n",
    "            \"\"\"\n",
    "                INSERT INTO AnimeInfo (id, title, score, genres, type, episodes, producers, rating)\n",
    "                VALUES(\n",
    "                    :id, :title, :score, :genres, :type, :episodes, :producers, :rating\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "insert_data(conn, \n",
    "            data2, \n",
    "            \"\"\"\n",
    "                INSERT INTO AnimeStats (id, members, favorites, watching, completed, on_hold, \n",
    "                dropped, plan_to_watch, score_10, score_9, score_8, score_7, score_6, score_5, \n",
    "                score_4, score_3, score_2, score_1)\n",
    "                VALUES(\n",
    "                    :id, :members, :favorites, :watching, :completed, :on_hold, \n",
    "                    :dropped, :plan_to_watch, :score_10, :score_9, :score_8, :score_7, :score_6, :score_5, \n",
    "                    :score_4, :score_3, :score_2, :score_1\n",
    "                )\n",
    "            \"\"\")\n",
    "\n",
    "insert_data(conn, \n",
    "            data3, \n",
    "            \"\"\"\n",
    "                INSERT INTO UserRating (user_id, anime_id, rating, watching_status)\n",
    "                VALUES(\n",
    "                    :user_id, :anime_id, :rating, :watching_status\n",
    "                )\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82fa0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "def get_from_head_with_condition(conn, sort_col, n, condition):\n",
    "    cur = conn.cursor()\n",
    "    samples = cur.execute(f\"\"\"SELECT title,\n",
    "        score,\n",
    "        producers\n",
    "        FROM AnimeInfo WHERE {condition} ORDER BY {sort_col} DESC LIMIT {str(n)}\"\"\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "cur = get_from_head_with_condition(conn, 'rating', 12, 'score > 8')\n",
    "\n",
    "keys = ['title', 'author', 'genre', 'pages', 'published_year', 'isbn', 'rating', 'views']\n",
    "result = []\n",
    "for row in cur.fetchall():\n",
    "    result.append({keys[i]: str(e) for i, e in enumerate(row)})\n",
    "    \n",
    "with open(\"5_top_with_condition.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(result, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d8be81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "def get_freq(conn, col):\n",
    "    cur = conn.cursor()\n",
    "    freq = cur.execute(f\"\"\"SELECT \n",
    "        {col}, COUNT(*)\n",
    "        FROM UserRating GROUP BY {col}\"\"\")\n",
    "    return freq\n",
    "\n",
    "freq = get_freq(conn, 'watching_status')\n",
    "freq = {e[0]: str(e[1]) for e in freq}\n",
    "\n",
    "with open(\"5_freq.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(freq, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "824de28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "def get_from_head_both_ordered(conn, n, sort_col):\n",
    "    cur = conn.cursor()\n",
    "    samples = cur.execute(f\"\"\"SELECT AnimeInfo.title,\n",
    "        AnimeInfo.producers,\n",
    "        UserRating.watching_status\n",
    "        FROM AnimeInfo JOIN UserRating ON AnimeInfo.id = UserRating.anime_id\n",
    "        ORDER BY {sort_col}\n",
    "        DESC LIMIT {str(n)}\"\"\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "cur = get_from_head_both_ordered(conn, 12, 'UserRating.rating')\n",
    "\n",
    "keys = ['title', 'producers', 'watching_status']\n",
    "result = []\n",
    "for row in cur.fetchall():\n",
    "    result.append({keys[i]: str(e) for i, e in enumerate(row)})\n",
    "    \n",
    "with open(\"5_top_from_both_ordered.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump(result, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "581c4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "def delete_by_col(conn, column, value):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"DELETE FROM UserRating WHERE {column} = {value}\")\n",
    "    conn.commit()\n",
    "\n",
    "delete_by_col(conn, 'watching_status', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b957ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "def get_stats(conn, col):\n",
    "    cur = conn.cursor()\n",
    "    stats = cur.execute(f\"\"\"SELECT \n",
    "        SUM({col}), MIN({col}), MAX({col}), AVG({col})  \n",
    "        FROM AnimeInfo\"\"\")\n",
    "    return stats.fetchone()\n",
    "\n",
    "stats = get_stats(conn, 'score')\n",
    "keys = ['sum', 'min', 'max', 'avg']\n",
    "\n",
    "with open(\"5_stats.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump({keys[i]: str(e) for i, e in enumerate(stats)}, outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dd1c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "def get_stats_for_categories(conn, col):\n",
    "    cur = conn.cursor()\n",
    "    stats = cur.execute(f\"\"\"SELECT \n",
    "        rating, SUM({col}), MIN({col}), MAX({col}), AVG({col}), COUNT(*)  \n",
    "        FROM AnimeInfo GROUP BY rating\"\"\")\n",
    "    return stats.fetchall()\n",
    "\n",
    "stats = get_stats_for_categories(conn, 'score')\n",
    "keys = ['category', 'sum', 'min', 'max', 'avg', 'count']\n",
    "\n",
    "with open(\"5_stats_for_categories.json\", \"w\", encoding=\"utf-8\") as outfile: \n",
    "    json.dump([{keys[i]: str(e) for i, e in enumerate(category)} for category in stats], outfile, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ae5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
